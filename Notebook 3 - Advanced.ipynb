{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advance Section Activities (ML Classification Techniques):\n",
    "\n",
    "\n",
    "### Andy and Juan Notes to Complete in Notebook\n",
    "### Delete once finished\n",
    "1. ML basics\n",
    "    * Explain what training means\n",
    "    * Explain overfitting / variance\n",
    "    * Evaluation on testing data\n",
    "* Logistic Regression or Classification \n",
    "    * Use age vs. (other)\n",
    "* Clustering\n",
    "    * K nearest neighbor \n",
    "    * Gaussian Mixture Model \n",
    "    * DBSCAN (density based)\n",
    "    * Explain strengths / weaknesses of each\n",
    "* Use dimension reduction to visualize clusters\n",
    "    * Briefly explain dimension reduction\n",
    "    * Add label coloring to clusters\n",
    "* SVM??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This is the expert level notebook for the Data Science (DS) and Machine Learning (ML) FredHutch.io tutorial, where we will work through beginning to end on different aspects and techniques in DS and ML for Research and Analysis.\n",
    "\n",
    "In this notebook we will work through Machine Learning techniques and strategies on the genes data (datasets available [here](https://www.dropbox.com/sh/jke9h4km90ner9l/AAD1UyucvlXIFbKTjl-D15U6a?dl=0)) from the same five cancer types (BRCA, KIRC, COAD, LUAD, PRAD) from the TCGA projects available from the [National Cancer Institute's Genomic Data Commons](https://gdc.cancer.gov/). \n",
    "\n",
    "We will keep working with *python libraries* introduced in the Beginner and Intermediate Tutorials and introduce some new libraries with special purposes in **Machine Learning**.\n",
    "> **Libraries Used in This Tutorial**\n",
    "* Data Manipulation and Processing\n",
    "     - [pandas]( https://pandas.pydata.org/)\n",
    "     - [numpy]( https://numpy.org/)\n",
    "* Data Visualization\n",
    "\t- [Matplotlib](https://matplotlib.org/)\n",
    "    - [Seaborn](https://seaborn.pydata.org/)\n",
    "    - [Altair](https://altair-viz.github.io/)\n",
    "* Statistics\n",
    "    - [Scipy](https://www.scipy.org/)\n",
    "    - [Statsmodels](https://www.statsmodels.org/stable/index.html)\n",
    "* Machine Learning\n",
    "    - [Scikit-Learn](https://scikit-learn.org/stable/)\n",
    "    \n",
    "In this notebook we will be focusing specifically on Machine Learning modeling in **python**. We'll primariy focus in:\n",
    "* Introducing what Machine Learning is\n",
    "* Fundamental concepts and techniques in ML\n",
    "* Introduce and familiarize with using **Scikit-Learn**\n",
    "* Fundamental categories of models\n",
    "* Some specific examples with regression and clustering ML models.\n",
    "\n",
    "# Table of Contents\n",
    "[1. Backgroud on Machine Learning: What is Machine Learning?](#1.-Backgroud-on-Machine-Learning:-What-is-Machine-Learning?)\n",
    "* [1.1 Types of Machine Learning Models](#1.1-Types-of-Machine-Learning-Models)\n",
    "    * [1.1.1 Supervised Machine Learning](#1.1.1-Supervised-Machine-Learning)\n",
    "    * [1.1.2 Unsupervised Machine Learning](#1.1.2-Unsupervised-Machine-Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Backgroud on Machine Learning: _What is Machine Learning?_\n",
    "\n",
    "In the world of analytics and specifically Data Science, _\"Machine Learning\"_ is so ubiquitos and a big buzzword thrown all over. Sometimes in the context of _\"We use ML in our (insert product)!\"_ or _\"Just use ML and you'll get the answer\",_ being almost this esoteric concept in Data Science often associated as part of AI.\n",
    "\n",
    "A better way of viewing Machine Learning is as the union of the concepts of computer programming (Beginner Notebook) and statistical concepts (Intermediate Notebook) in Data Science. The primary idea to remember is that we are building models out of data, where our models \"learn\" or become tuned from data and then can make predictions on similar but never before seen data.  \n",
    "\n",
    "\n",
    "## 1.1 Types of Machine Learning Models\n",
    "\n",
    "There are a large variety of Machine Learning models available for us work with, but it is important to always remember that our problem or question at hand will dictate the type of models we can use. In other words, _don’t try to paint a wall with a hammer_ or _screw on a shelf with a saw_ , each tool has a best use scenario. It might sound enticing to use a fancy sounding model say “K-Means” or “Support Vector Machine” for your research, but if you are trying to predict effects of drug dosage on how fast a cancer metastasize, you might be using the wrong tool for the job.\n",
    "\n",
    "Let’s first discuss the two main types Machine Learning algorithms are categorized into: [_Supervised_](https://en.wikipedia.org/wiki/Supervised_learning) and [_Unsupervised_](https://en.wikipedia.org/wiki/Unsupervised_learning) .\n",
    "\n",
    "### 1.1.1 Supervised Machine Learning\n",
    "\n",
    "Recall that Machine Learning is our models “learning” from our data, hence _Supervised Machine Learning_ would be a model that “learns” from data that has some labels already attached to it. Some of the models that fall under this type of ML are _Regression_ and _Classification_ , such as Linear Regression model with continuous data to predict a continuous value (age, dosage, time, etc) or Logistic Regression for classifying values (sex, smoker, education level, etc).  If our data has labels already attach to them and we want to figure out the relation of a target variable to these labels, then we are dealing with a Supervised Learning problem.\n",
    "\n",
    "### 1.1.2 Unsupervised Machine Learning\n",
    "\n",
    "Given that Supervised Learning requires labels for our data, _Unsupervised Machine Learning_ is the name given to models that use unlabeled data, which mainly means we “omit” labels that might exist in our data, allowing the model to learn patterns from some features. These types of models tend to be used for _Clustering_ or for _Dimension Reduction_ purposes.\n",
    "\n",
    "## 1.2 Key Basic ML Ideas and Concepts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# visualization\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# setting up the plot style\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_genes_subset(split_size=.1):\n",
    "    \"\"\"\n",
    "        Creates a smaller dataframe from the large 'genes.csv' file based on a split from the metadata file.\n",
    "        Returns a dataframe that has been transformed by log2 and the index needed for the remaining samples\n",
    "        from the genes.csv file to remain independent.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    metadata = pd.read_csv('../metadata.csv')\n",
    "    \n",
    "    big_split, small_split = train_test_split(metadata, test_size=split_size, random_state=4)\n",
    "    \n",
    "    skiplines_small = np.sort(big_split.index) + 1 \n",
    "    skiplines_big = np.sort(small_split.index) + 1\n",
    "    \n",
    "    genes_small = pd.read_csv('../genes.csv', skiprows=skiplines_small)\n",
    "    \n",
    "    genes_nonAllZero = genes_small.loc[:,~genes_small.isin([0]).all(axis=0)]\n",
    "    \n",
    "    genes_log2_trans = np.log2(genes_nonAllZero.iloc[:,1:] + 1)\n",
    "    genes_log2_trans['barcode'] = genes_small['barcode']\n",
    "    \n",
    "    genes_merged = pd.merge(left=small_split, right=genes_log2_trans, how='left', left_on='barcode', right_on='barcode')\n",
    "    \n",
    "    return genes_merged, big_split, small_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data558] *",
   "language": "python",
   "name": "conda-env-data558-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
